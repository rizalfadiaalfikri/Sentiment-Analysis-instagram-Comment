{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "\n",
    "sw_indo = stopwords.words(\"indonesian\") + list(punctuation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Instagram Comment Text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>negative</td>\n",
       "      <td>&lt;USERNAME&gt; TOLOL!! Gak ada hubungan nya kegug...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>negative</td>\n",
       "      <td>Geblek lo tata...cowo bgt dibela2in balikan......</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negative</td>\n",
       "      <td>Kmrn termewek2 skr lengket lg duhhh kok labil ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>negative</td>\n",
       "      <td>Intinya kalau kesel dengan ATT nya, gausah ke ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>negative</td>\n",
       "      <td>hadewwwww permpuan itu lg!!!!sakit jiwa,knp ha...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sentiment                             Instagram Comment Text\n",
       "Id                                                             \n",
       "1   negative   <USERNAME> TOLOL!! Gak ada hubungan nya kegug...\n",
       "2   negative  Geblek lo tata...cowo bgt dibela2in balikan......\n",
       "3   negative  Kmrn termewek2 skr lengket lg duhhh kok labil ...\n",
       "4   negative  Intinya kalau kesel dengan ATT nya, gausah ke ...\n",
       "5   negative  hadewwwww permpuan itu lg!!!!sakit jiwa,knp ha..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"Dataset/dataset_komentar_instagram_cyberbullying.csv\", index_col=\"Id\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment                 400\n",
       "Instagram Comment Text    400\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[\"Instagram Comment Text\"]\n",
    "y = df.Sentiment\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithm: Logistic Regresion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:   12.4s finished\n",
      "C:\\Users\\ASUS\\Miniconda3\\envs\\jcopml\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1.0, 0.8857142857142858, 0.8583333333333333)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(tokenizer=word_tokenize, stop_words=sw_indo)),\n",
    "    ('algo',LogisticRegression())\n",
    "])\n",
    "\n",
    "\n",
    "#Hyperparameter Tuning\n",
    "parameter = {\n",
    "    \"algo__fit_intercept\" : [True,False],\n",
    "    \"algo__C\" : range(1,5,1)\n",
    "}\n",
    "\n",
    "#Training\n",
    "model = GridSearchCV(estimator=pipeline, param_grid=parameter, cv=5, n_jobs=-1, verbose=1)\n",
    "model.fit(X_train,y_train)\n",
    "model.score(X_train,y_train), model.best_score_, model.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction: Logistic Regresion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_predict = [\n",
    "    [\"Dari pada loe beban keluarga, ga guna, ga usah hidup aja sekalian\"], #negative Comment\n",
    "    [\"Kamu hari ini terlihat cantik banget\"] #positive Comment\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['negative'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_predict[0]) # Predict Negative Comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['positive'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_predict[1]) # Predict positive Comment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithm: KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 200 candidates, totalling 600 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    5.9s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:   28.0s\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 600 out of 600 | elapsed:  1.4min finished\n",
      "C:\\Users\\ASUS\\Miniconda3\\envs\\jcopml\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1.0, 0.8750476626248761, 0.85)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(tokenizer=word_tokenize, stop_words=sw_indo)),\n",
    "    ('algo',KNeighborsClassifier())\n",
    "])\n",
    "\n",
    "#Hyperparameter Tunning\n",
    "parameter = {\n",
    "    \"algo__n_neighbors\" : range(1,51,1),\n",
    "    \"algo__weights\" : [\"distance\",\"uniform\"],\n",
    "    \"algo__p\" : [1,2]\n",
    "}\n",
    "\n",
    "#Training\n",
    "model = GridSearchCV(estimator=pipeline, param_grid=parameter, cv=3, n_jobs=-1, verbose=1)\n",
    "model.fit(X_train,y_train)\n",
    "model.score(X_train,y_train), model.best_score_, model.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction: KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_predict = [\n",
    "    [\"Dari pada loe beban keluarga, ga guna, ga usah hidup aja sekalian\"], #negative Comment\n",
    "    [\"Kamu hari ini terlihat cantik banget\"] #positive comment\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['negative'], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_predict[0]) # Predict Negative Comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['positive'], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_predict[1]) # Predict positive Comment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithm: SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 125 candidates, totalling 375 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    7.9s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:   34.8s\n",
      "[Parallel(n_jobs=-1)]: Done 375 out of 375 | elapsed:  1.1min finished\n",
      "C:\\Users\\ASUS\\Miniconda3\\envs\\jcopml\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1.0, 0.8749332723251735, 0.8583333333333333)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(tokenizer=word_tokenize, stop_words=sw_indo)),\n",
    "    ('algo',SVC(max_iter=500))\n",
    "])\n",
    "\n",
    "#Hyperparameter Tunning\n",
    "parameter = {\n",
    "    \"algo__kernel\" : ['linear', 'poly', 'rbf', 'sigmoid', 'precomputed'],\n",
    "    \"algo__C\" : [0.001, 0.01, 0.1, 1, 10],\n",
    "    \"algo__gamma\" : ['scale',10, 5, 1, 0.1]\n",
    "}\n",
    "\n",
    "#Training\n",
    "model = GridSearchCV(estimator=pipeline, param_grid=parameter, cv=3, n_jobs=-1, verbose=1)\n",
    "model.fit(X_train,y_train)\n",
    "model.score(X_train,y_train), model.best_score_, model.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction: SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_predict = [\n",
    "    [\"Dari pada loe beban keluarga, ga guna, ga usah hidup aja sekalian\"], #negative Comment\n",
    "    [\"Kamu hari ini terlihat cantik banget\"] #positive Comment\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['negative'], dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_predict[0]) # Predict Negative Comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['positive'], dtype=object)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_predict[1]) # Predict positive Comment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kesimpulan\n",
    "\n",
    "Akurasi yang dihasilkan dengan menggunakan Algoritma Logistic Regresion, KNN, SVM tidak jauh berbeda, rata - rate score yang dihasilkan berada di angka 0.85, akan tetapi dari segi proses training Logistic Regresion lebih baik dari KNN dan SVM karena waktu yang dibutuhkan Logistic Regresion lebih cepat dari KNN dan SVM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:jcopml]",
   "language": "python",
   "name": "conda-env-jcopml-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
